# DOCKERFILE - Application FastAPI MLOps

```dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ³ DOCKERFILE - Application FastAPI MLOps
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ğŸ¯ OBJECTIF
# Conteneuriser l'application FastAPI avec toutes ses dÃ©pendances pour garantir
# un environnement reproductible (dev = prod). OptimisÃ© pour production avec
# image lÃ©gÃ¨re, layers en cache, et healthcheck intÃ©grÃ©.
#
# ğŸ“š CONCEPTS CLÃ‰S
# - Multi-stage builds : non utilisÃ© ici (app simple), mais Ã  considÃ©rer si >500MB
# - Layer caching : ordre COPY optimisÃ© (dÃ©pendances avant code)
# - Image slim : -60% vs image standard Python
# - Healthcheck : vÃ©rification automatique de l'Ã©tat du conteneur
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FROM python:3.11-slim
# ğŸ“¦ IMAGE DE BASE : Python 3.11 version "slim"
# 
# POURQUOI 3.11 ?
# - Performance : +25% vs 3.10 (PEP 659 - specialized adaptive interpreter)
# - CompatibilitÃ© : TensorFlow 2.15+, FastAPI 0.100+
# - Support LTS : sÃ©curitÃ© garantie jusqu'en 2027
#
# POURQUOI SLIM ?
# - Taille : ~120MB (vs ~900MB pour python:3.11 standard)
# - Debian-based : compatible avec apt-get (vs Alpine qui utilise apk)
# - Compromis : librairies de base prÃ©sentes, pas de bloat inutile
# 
# ALTERNATIVES
# - python:3.11-alpine : ultra-lÃ©ger (~50MB) mais compilations complexes (TensorFlow)
# - python:3.11 : toutes les libs systÃ¨me, utile pour debug mais lourd en prod

WORKDIR /app
# ğŸ“ RÃ‰PERTOIRE DE TRAVAIL
# Tous les COPY et RUN suivants s'exÃ©cutent depuis /app
# Ã‰quivalent Ã  : RUN mkdir -p /app && cd /app

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ INSTALLATION DÃ‰PENDANCES SYSTÃˆME
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RUN apt-get update && apt-get install -y \
    curl \
    # ğŸ©º curl : nÃ©cessaire pour HEALTHCHECK (test endpoint /health)
    # Alternative : wget, mais curl plus standard pour API testing
    && rm -rf /var/lib/apt/lists/*
    # ğŸ§¹ NETTOYAGE : supprime cache apt (~100MB Ã©conomisÃ©s)
    # /var/lib/apt/lists/ contient les mÃ©tadonnÃ©es des packages
    # Bonne pratique : TOUJOURS nettoyer dans la mÃªme layer (optimisation taille)

# ğŸ’¡ OPTIMISATION LAYER CACHING
# apt-get update && install && rm dans un SEUL RUN :
# âœ… 1 layer au lieu de 3 â†’ image plus petite
# âœ… Cache invalide si dÃ©pendances changent â†’ rebuild propre

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š INSTALLATION DÃ‰PENDANCES PYTHON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COPY requirements/base.txt requirements/prod.txt requirements/monitoring.txt ./
# ğŸ“‹ COPIE SÃ‰PARÃ‰E DES REQUIREMENTS (avant le code source)
# 
# POURQUOI CETTE ORDRE ?
# Docker met en cache chaque layer. Si requirements changent â†’ rebuild.
# Mais si SEUL le code change â†’ rÃ©utilise cache pip (gain de temps Ã©norme)
#
# STRATÃ‰GIE DE REQUIREMENTS
# - base.txt : dÃ©pendances core (FastAPI, TensorFlow, SQLAlchemy)
# - prod.txt : outils production (gunicorn, uvicorn workers)
# - monitoring.txt : Prometheus client, psutil
# SÃ©paration = clartÃ© + rÃ©utilisabilitÃ© (ex: base.txt partagÃ© avec notebooks)

RUN pip install --no-cache-dir \
    -r base.txt \
    -r prod.txt \
    -r monitoring.txt
# ğŸ INSTALLATION AVEC PIP
#
# --no-cache-dir : ne stocke PAS les wheels tÃ©lÃ©chargÃ©s (~300MB Ã©conomisÃ©s)
# En prod, pas besoin de cache (build une fois, run partout)
#
# ORDRE D'INSTALLATION
# 1. base.txt (dÃ©pendances lourdes : TensorFlow ~400MB)
# 2. prod.txt (lÃ©ger : gunicorn, uvloop)
# 3. monitoring.txt (lÃ©ger : prometheus-client)
# â†’ Si monitoring change, pas de retÃ©lÃ©chargement de TensorFlow (cache layer)

# ğŸ’¡ ALTERNATIVE POUR TRÃˆS GROSSES IMAGES
# Multi-stage build (non nÃ©cessaire ici) :
#   FROM python:3.11-slim AS builder
#   RUN pip install --user ...
#   FROM python:3.11-slim
#   COPY --from=builder /root/.local /root/.local
# Permet de sÃ©parer outils de build vs runtime (~30% gain supplÃ©mentaire)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ COPIE DU CODE SOURCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COPY src/ ./src/
COPY scripts/ ./scripts/
COPY config/ ./config/
# ğŸ“ COPIE SÃ‰LECTIVE (pas de COPY . .)
#
# STRUCTURE PRÃ‰SERVÃ‰E DE LA V2
# /app/
#   â”œâ”€â”€ src/        â†’ code mÃ©tier (api/, models/, monitoring/)
#   â”œâ”€â”€ scripts/    â†’ run_api.py (entrypoint)
#   â””â”€â”€ config/     â†’ settings.py
#
# POURQUOI PAS "COPY . ." ?
# âŒ Copierait aussi : .git/, tests/, notebooks/, __pycache__/, .env
# âœ… Copie sÃ©lective = image propre + sÃ©curitÃ© (pas de secrets accidentels)
# 
# ORDRE STRATÃ‰GIQUE
# CopiÃ© EN DERNIER = invalidation cache uniquement si code change
# Si requirements inchangÃ©s â†’ build ultra-rapide (rÃ©utilise layers pip)

# âš ï¸ FICHIERS NON COPIÃ‰S (gÃ©rÃ©s par volumes Docker Compose)
# - data/ : dataset montÃ© en read-only (../data:/app/data:ro)
# - models/ : fichier .h5 montÃ© en read-only (../models:/app/models:ro)
# Avantage : update modÃ¨le sans rebuild image (juste restart conteneur)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ EXPOSITION DU PORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXPOSE 8000
# ğŸ“¡ DOCUMENTATION DU PORT (mÃ©tadonnÃ©e uniquement)
#
# âš ï¸ EXPOSE NE PUBLIE PAS LE PORT !
# C'est docker run -p 8000:8000 ou docker-compose ports: qui le fait
# RÃ´le : documenter l'intention (quel port l'app utilise)
#
# Standard FastAPI : 8000 (convention, modifiable via uvicorn --port)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¥ HEALTHCHECK - Surveillance automatique
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1
# ğŸ©º VÃ‰RIFICATION PÃ‰RIODIQUE DE L'Ã‰TAT DU CONTENEUR
#
# PARAMÃˆTRES
# --interval=30s : frÃ©quence des checks (toutes les 30s aprÃ¨s start-period)
# --timeout=10s : durÃ©e max d'un check (infÃ©rence CNN peut Ãªtre lente)
# --start-period=40s : grace period (permet chargement modÃ¨le TensorFlow)
# --retries=3 : nombre d'Ã©checs avant status "unhealthy"
#
# COMMANDE DE TEST
# curl -f http://localhost:8000/health
#   -f : fail (exit code â‰  0) si HTTP status â‰  2xx/3xx
#   || exit 1 : force exit code 1 si curl Ã©choue
#
# ENDPOINT /health REQUIS (Ã  implÃ©menter dans FastAPI)
# Exemple de rÃ©ponse :
#   {
#     "status": "healthy",
#     "database": "connected",
#     "model": "loaded",
#     "timestamp": "2025-11-16T10:30:00Z"
#   }
#
# Ã‰TATS RÃ‰SULTANTS
# - starting : pendant start-period (40s)
# - healthy : check rÃ©ussi
# - unhealthy : 3 Ã©checs consÃ©cutifs (3Ã—30s = 90s)
#
# ğŸ’¡ UTILISATION PAR DOCKER COMPOSE
# depends_on avec condition: service_healthy attend ce healthcheck

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ COMMANDE DE DÃ‰MARRAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CMD ["python", "scripts/run_api.py"]
# ğŸƒ ENTRYPOINT DE L'APPLICATION
#
# POURQUOI run_api.py (et pas directement uvicorn) ?
# âœ… CohÃ©rence avec V2 (mÃªme point d'entrÃ©e)
# âœ… FlexibilitÃ© : peut inclure setup prÃ©-dÃ©marrage (logging, warmup modÃ¨le)
# âœ… Configuration centralisÃ©e (workers, host, port dans le script)
#
# CONTENU TYPIQUE DE run_api.py :
#   import uvicorn
#   if __name__ == "__main__":
#       uvicorn.run(
#           "src.api.main:app",
#           host="0.0.0.0",      # Ã©coute sur toutes interfaces (requis Docker)
#           port=8000,
#           workers=4,           # multi-processing (production)
#           log_level="info"
#       )
#
# FORMAT EXEC vs SHELL
# ["python", "..."] = exec form (RECOMMANDÃ‰)
#   âœ… PID 1 = python (gestion signaux propre : SIGTERM â†’ graceful shutdown)
#   âœ… Pas de shell intermÃ©diaire
# "python ..." = shell form
#   âŒ PID 1 = /bin/sh (ne transmet pas SIGTERM correctement)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ CONCEPTS AVANCÃ‰S (non implÃ©mentÃ©s ici, pour aller plus loin)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# 1. UTILISATEUR NON-ROOT (sÃ©curitÃ©)
#    RUN useradd -m appuser
#    USER appuser
#    â†’ Ã‰vite exÃ©cution en root (principe du moindre privilÃ¨ge)
#
# 2. MULTI-STAGE BUILD (optimisation taille)
#    FROM python:3.11-slim AS builder
#    RUN pip install --user -r requirements.txt
#    FROM python:3.11-slim
#    COPY --from=builder /root/.local /root/.local
#    â†’ SÃ©pare build vs runtime (supprime gcc, headers, etc.)
#
# 3. LABELS (mÃ©tadonnÃ©es)
#    LABEL maintainer="remi@example.com"
#    LABEL version="3.0.0"
#    LABEL description="CV Cats/Dogs MLOps API"
#    â†’ TraÃ§abilitÃ© (docker inspect montre les labels)
#
# 4. ARG POUR VERSIONS DYNAMIQUES
#    ARG PYTHON_VERSION=3.11
#    FROM python:${PYTHON_VERSION}-slim
#    â†’ Build avec diffÃ©rentes versions Python
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ COMMANDES BUILD & DEBUG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# BUILD
#   docker build -t cv-app:v3 -f docker/Dockerfile.app .
#   docker build --no-cache ...  # force rebuild sans cache
#
# INSPECTION
#   docker history cv-app:v3     # voir taille de chaque layer
#   docker inspect cv-app:v3     # mÃ©tadonnÃ©es complÃ¨tes
#
# DEBUG
#   docker run -it cv-app:v3 bash           # shell interactif
#   docker run cv-app:v3 python --version   # override CMD
#
# OPTIMISATION
#   docker images | grep cv-app              # vÃ©rifier taille finale
#   dive cv-app:v3                           # analyser layers (outil externe)
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```